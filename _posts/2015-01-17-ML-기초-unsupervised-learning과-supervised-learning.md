---
title: "ML 기초: unsupervised learning과 supervised learning"
categories: [tech, machine-learning]
tags: [machine-learning, supervised-learning, unsupervised-learning]
mathjax: true
---

기계학습에 관한 정의는 여러가지가 있다. 개인적으로는 관측한 데이터로부터 일반적인 명제를 도출하기 위한 알고리즘을 연구하는 분야라고 말하고 싶다. 기계에게 알고리즘이라는 생각의 틀과 현상을 기술하는 자료들을 쥐어주면, 그 속에서 유의미한 패턴을 찾아내는 "학습"을 진행하는 것 이다. 올바른 샘플을 많이 확보 할 수록, 데이터 생성에 기저한 규칙을 보다 잘 설명할 수 있다는 사실은 자명하지만, 기계 학습의 초기 단계에는 다수의 학습용 샘플을 확보하는 작업이 지금보다 힘들었다. 가용한 컴퓨팅 파워 또한 제한적이었던 만큼, perceptron을 필두로 하는 초기의 모델들은 적은 데이터를 적은 리소스의 컴퓨터에서 가동해야 한다는 한계를 가지고 단순한 형태로 개발 될 수 밖에 없었다.

하지만 기계학습의 태동 이후로 50년이 지난 지금은 폭발적인 양의 데이터를 대용량 분산 환경에서 다룰 수 있게 되었고, 이에 따라 효율적인 분산 처리 기법들과 이전보다 정교한 모델링이 필요하게 되었다. 그 동안 기계학습 모델에는 많은 진보가 있었지만, “데이터에 기반한 학습”이라는 기본적인 원칙은 여전히 변함이 없으며, 새로이 제안되는 방법론들도 거의 모두가 이전 모델들의 아이디어를 확장하고 조합해서 얻어지는 결과물이라고 할 수 있다. 최신의 알고리즘들을 먼저 소개하고 싶기도 했지만, 우선은 기계학습(machine learning, ML)의 기초에 대한 글 하나 정도는 있으면 좋겠다는 생각이 들었다. 오늘은 가장 기본적인 개념 중 하나를 설명해 보려고 한다.

- 자율학습unsupervised learning과 교사학습(supervised learning)

학습용 데이터는 대부분 관측(observation 혹은 measurement)과 정답(label 혹은 class) 두 가지로 표현된다. 관측은 우리가 취득한 데이터 그 자체를 의미하는데, 예를 들어 음성 처리에서는 음의 높고 낮음을 시간의 흐름에 따라 기록한 시계열 데이터가 관측 신호이고, 영상 처리에서는 RGB 값들로 이루어진 사진이 관측 데이터이다. 정답은 관측과 쌍을 이루는 부가정보로써, 관측 값들로부터 도출 하고자 하는 출력 값(desired value 혹은 target value)을 의미한다. 음성 신호를 취득하여 어떤 사람의 음성인지 인지하는 알고리즘을 작성하기 위해서는, 음성 시계열 데이터와 함께 그것이 누구의 목소리인지에 대한 정답이 쌍으로 존재해야 할 것이다. 무엇에 대한 사진인지 학습을 하려면 마찬가지로 사진과 쌍을 이루는 태그들이 있어야 한다.

관측데이터와 정답을 나타내기 위한 다양한 표기법이 존재하는데, 이 글에서는 가장 일반적인 표기법 중 하나인 $$ (X,Y) $$를 사용하기로 한다. 즉, 관측데이터는 $$ d $$차원 벡터 집합 $$ X = \{ x_1, \ldots, x_N \| x_i \in R^d \} $$ 으로, 정답은 $$ Y = \{ y_1, \ldots, y_N \} $$ 으로 각각 기술한다. 많은 경우에 있어서, $$ X $$를 취득하는 것 보다 $$ Y $$를 확보하는 것이 상대적으로 어려운데, 그 이유는 사람이 원하는 출력 값은 대부분 사람이 지정해 줄 수 밖에 없기 때문이다.

이러한 맥락에서, $$ Y $$가 없는 상황에서 $$ X $$만을 이용하는 모델링 기법들이 제안되었는데 이를 자율학습(unsupervised learning)이라고 하고, $$ (X,Y) $$ 쌍을 모두 활용하는 학습 방식을 교사학습(supervised learning)이라 한다. 그렇다면, 관측 $$ X $$만으로 학습하는 자율학습보다 정답 $$ Y $$가 추가적으로 주어지는 교사학습이 실제 데이터 생성의 규칙에 보다 근접한 답을 도출 할 수 있을까? 부가 정보가 더 있기 때문에 그럴 것이다라고 쉽게 예상이 되지만, 단순하게 비교하기는 어렵다. 그 이유는 첫째로 $$ Y $$에 사람의 실수로 에러가 포함되어있을 수 있고, 둘째는 $$ X $$에 관측 에러가 존재할 수도 있으며, 셋째는 학습 모델의 복잡도가 자율학습 및 교사학습의 구분과 상관없이 천차만별이기 때문이다. 첫째와 둘째를 아울러서 data error라고 하고, 셋째는 model error와 관련된 설명이라고 할 수 있다. 변하지 않는 기본적인 명제는 데이터의 복잡도와 모델의 복잡도가 동일할 때 데이터를 가장 정확하게 설명하는 학습 결과가 나온다는 것이며, 두 복잡도 사이의 갭은 정확히 추정하는 것이 힘들기 때문에 자율학습과 교사학습 중 어느 것이 좋다고 말하는 것은 어려운 일이다. 이러한 이유로 자율학습과 교사학습은 한쪽에 치우치지 않고 양쪽이 고르게 발전되어 왔으며, 각각의 대표적인 예로 cluster analysis와 classification을 들 수 있다.

또한, 두 학습의 개념을 혼합한 반교사학습(semi-supervised learning)이 존재하는데, 주로 많은 수의 관측과 그 중 일부의 관측들만 정답을 가지고 있는 데이터에 적합한 방법론이다. 이 중 한가지는 많은 수의 unlabeled data(정답데이터가 쌍으로 존재하지 않는 관측데이터)를 가지고 교사학습을 진행한 결과를 labeled data(정답을 가지는 관측)로 생성한 모델과 비교하여 신뢰할만한 결과를 가지는 unlabeled data를 그것의 결과와 함께 labeled data로 편입시키는 방법이 있다.

이러한 구분 외에 강화학습(reinforcement learning)이라는 개념도 있다. 교사학습의 학습과는 다르게 관측과 machine의 상태에 따라 행동을 개시하면 환경으로부터 reward 혹은 punishment의 피드백 받아 행동 규칙을 개선해 나간다. 로봇 제어와 체스 게임과 같은 분야에 응용되는 것으로 알려져 있다.
